---
title: "AWS Bedrock"
description: "Configure AWS Bedrock models for use with Onyx"
icon: "aws"
---

# AWS Bedrock Configuration

AWS Bedrock is a fully managed service that offers a choice of high-performing foundation models from leading AI
companies. This guide will help you configure AWS Bedrock models in Onyx.

## Overview

AWS Bedrock provides access to a variety of foundation models through a unified API, including models from Anthropic,
AI21, Cohere, Meta, and others.
This allows you to choose the best model for your specific use case while maintaining a single integration point.

### Available Models

- **Anthropic Claude**: Claude 3 Sonnet, Claude 3 Haiku, Claude 3 Opus
- **AI21 Jurassic**: Jurassic-2 Ultra, Jurassic-2 Mid, Jurassic-2 Light
- **Cohere Command**: Command, Command Light, Command Night
- **Meta Llama**: Llama 2 70B, Llama 2 13B, Llama 2 7B
- **Amazon Titan**: Titan Text Express, Titan Text Lite, Titan Embeddings
- **Stability AI**: Stable Diffusion XL

## Prerequisites

Before configuring AWS Bedrock in Onyx, ensure you have:

- **AWS Account**: An active AWS account with billing enabled
- **IAM Permissions**: Proper IAM roles and policies for Bedrock access
- **Model Access**: Access to the specific models you want to use
- **AWS Credentials**: Access keys or IAM roles for authentication

## Configuration Steps

### Step 1: Set Up AWS Bedrock

<Steps>
  <Step title="Enable Bedrock Service">
    - Log into the AWS Management Console
    - Navigate to Amazon Bedrock
    - Click "Get started" to enable the service
  </Step>

  <Step title="Request model access">
    - Go to the Model access section
    - Request access to the models you want to use
    - Wait for approval (usually instant for most models)
  </Step>

  <Step title="Configure IAM permissions">
    - Create an IAM user or role with Bedrock permissions
    - Attach the `AmazonBedrockFullAccess` policy or create a custom policy
  </Step>
</Steps>

### Step 2: Create IAM Policy

Create a custom IAM policy for Bedrock access:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "bedrock:InvokeModel",
                "bedrock:InvokeModelWithResponseStream",
                "bedrock:ListFoundationModels",
                "bedrock:GetFoundationModel"
            ],
            "Resource": "*"
        }
    ]
}
```

### Step 3: Configure in Onyx

<Steps>
  <Step title="Open LLM config">
    Navigate to the Onyx admin panel
  </Step>

  <Step title="Select AWS Bedrock">
    Go to **LLM Config** > **AWS Bedrock**
  </Step>

  <Step title="Choose authentication method">
    - **Access Keys**: Enter AWS Access Key ID and Secret Access Key
    - **IAM Role**: Use IAM role-based authentication (recommended for production)
  </Step>

  <Step title="Select region">
    Select your preferred AWS region
  </Step>

  <Step title="Choose models">
    Choose the models you want to enable
  </Step>

  <Step title="Configure parameters">
    Configure model-specific parameters
  </Step>
</Steps>

## Model Configuration

### Model Selection

Choose the appropriate Bedrock models based on your use case:

#### Text Generation Models

- **Claude 3 Opus**: Most capable model for complex reasoning
- **Claude 3 Sonnet**: Balanced performance and cost
- **Claude 3 Haiku**: Fast and efficient for simple tasks
- **Jurassic-2 Ultra**: Strong performance for creative tasks
- **Command**: Good for instruction following and chat

#### Embedding Models

- **Titan Embeddings**: Amazon's embedding model
- **Cohere Embed**: Cohere's embedding model

### Parameters

Configure model parameters to optimize performance:

- **Temperature**: Controls randomness (0.0-1.0)
- **Max Tokens**: Maximum response length
- **Top P**: Nucleus sampling parameter
- **Top K**: Top-k sampling parameter
- **Stop Sequences**: Custom stop sequences for the model

### Model-Specific Settings

Different models may have specific configuration options:

#### Claude Models

```json
{
    "anthropic_version": "bedrock-2023-05-31",
    "max_tokens": 4096,
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 250
}
```

#### Jurassic Models

```json
{
    "maxTokens": 4096,
    "temperature": 0.7,
    "topP": 0.9,
    "stopSequences": ["\n\n"]
}
```

## Usage Examples

### Basic Text Generation

```python
# Example API call to Claude 3 Sonnet
{
    "modelId": "anthropic.claude-3-sonnet-20240229-v1:0",
    "contentType": "application/json",
    "accept": "application/json",
    "body": {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 4096,
        "messages": [
            {
                "role": "user",
                "content": "Explain quantum computing in simple terms"
            }
        ]
    }
}
```

### Streaming Responses

```python
# Example with streaming
{
    "modelId": "anthropic.claude-3-sonnet-20240229-v1:0",
    "contentType": "application/json",
    "accept": "application/json",
    "body": {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 4096,
        "messages": [
            {
                "role": "user",
                "content": "Write a short story about AI"
            }
        ]
    }
}
```

## Best Practices

### Cost Optimization

- **Model Selection**: Choose the right model size for your task
- **Token Management**: Monitor token usage and implement caching
- **Batch Processing**: Group similar requests when possible
- **Region Selection**: Use the closest region to minimize latency

### Performance Optimization

- **Connection Pooling**: Reuse connections for better performance
- **Caching**: Cache responses for frequently asked questions
- **Load Balancing**: Distribute requests across multiple models
- **Monitoring**: Track response times and success rates

### Security Considerations

- **IAM Roles**: Use IAM roles instead of access keys when possible
- **VPC Configuration**: Configure Bedrock to use your VPC for enhanced security
- **Encryption**: Ensure all data is encrypted in transit and at rest
- **Audit Logging**: Enable CloudTrail for API call logging

## Troubleshooting

### Common Issues

**Access Denied Errors**
- Verify IAM permissions are correctly configured
- Check if model access has been granted
- Ensure the AWS region supports the requested model

**Model Not Available**
- Check if the model is available in your selected region
- Verify model access has been requested and approved
- Check AWS service status for any outages

**Authentication Errors**
- Verify AWS credentials are correct and have proper permissions
- Check if credentials have expired
- Ensure the IAM user/role has Bedrock permissions

### Error Handling

Implement proper error handling for common scenarios:

```python
try:
    response = bedrock_client.invoke_model(request)
except ClientError as e:
    error_code = e.response['Error']['Code']
    if error_code == 'AccessDeniedException':
        # Handle permission issues
        check_iam_permissions()
    elif error_code == 'ModelNotAccessibleException':
        # Handle model access issues
        request_model_access()
    elif error_code == 'ThrottlingException':
        # Handle rate limiting
        implement_backoff_strategy()
```

## Monitoring and Analytics

### CloudWatch Metrics

Monitor Bedrock usage with CloudWatch:

- **InvocationCount**: Number of model invocations
- **InvocationLatency**: Time taken for model responses
- **Invocation4XXErrors**: Client error count
- **Invocation5XXErrors**: Server error count

### Cost Monitoring

Track costs using AWS Cost Explorer:

- **Service**: Amazon Bedrock
- **Usage Type**: Model-specific usage
- **Region**: Geographic distribution of costs

### Logging

Enable comprehensive logging:

- **CloudTrail**: API call logging for compliance
- **CloudWatch Logs**: Application-level logging
- **Custom Metrics**: Business-specific metrics

## Integration with Onyx

### Chat Interface

Configure Bedrock models for use in Onyx's chat interface:

- Set as default model for general conversations
- Configure model-specific parameters
- Enable model switching for users
- Set up fallback options

### Agent Configuration

Use Bedrock models with Onyx agents:

- Assign specific Bedrock models to agents
- Configure custom instructions for each agent
- Set up model-specific prompts and templates
- Enable streaming responses where appropriate

### Document Processing

Leverage Bedrock's capabilities for document analysis:

- Configure for document summarization
- Enable question answering from documents
- Set up content extraction and analysis
- Use embedding models for semantic search

## Advanced Configuration

### VPC Configuration

For enhanced security, configure Bedrock to use your VPC:

- Create a VPC endpoint for Bedrock
- Configure security groups and network ACLs
- Update IAM policies to restrict access to the VPC
- Test connectivity from your application

### Multi-Region Setup

For high availability and compliance:

- Configure Bedrock in multiple regions
- Implement region selection logic
- Set up cross-region failover
- Monitor costs across regions

### Custom Models

For enterprise deployments:

- Train custom models using SageMaker
- Deploy models to Bedrock
- Configure custom model access
- Implement model versioning

## Next Steps

After configuring AWS Bedrock in Onyx:

- **Test the Integration**: Verify that models are working correctly
- **Monitor Performance**: Track response times and success rates
- **Optimize Costs**: Monitor usage and adjust model selection
- **Train Users**: Educate users on Bedrock's capabilities
- **Scale Usage**: Gradually increase usage while monitoring performance

For additional support or questions about AWS Bedrock integration,
refer to the [AWS Bedrock documentation](https://docs.aws.amazon.com/bedrock/) or contact the Onyx support team.
