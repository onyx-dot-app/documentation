---
title: OpenAI
description: "Configure OpenAI models for Onyx"
---

Configure Onyx to use OpenAI's GPT models, providing high-quality language generation with reliable performance. OpenAI offers the most popular and widely-used LLMs including GPT-4, GPT-4o, and GPT-3.5-turbo.

## Available Models

OpenAI provides several model options through their API:

### **GPT-4 Family**
- **GPT-4** - Most capable model with excellent reasoning and complex task performance
- **GPT-4o** - Optimized version with better speed and cost efficiency while maintaining quality
- **GPT-4 Turbo** - Faster processing with larger context window support

### **GPT-3.5 Family**
- **GPT-3.5-turbo** - Fast and cost-effective for many tasks
- **GPT-3.5-turbo-16k** - Extended context window for longer documents

### **Model Recommendations**
- **Production Use**: GPT-4 or GPT-4o for best quality
- **Cost-Conscious**: GPT-3.5-turbo for simpler tasks
- **High Volume**: GPT-4o for balanced performance and cost

## Configuration Setup

### **1. Get OpenAI API Key**

1. Visit the [OpenAI Developer Platform](https://platform.openai.com/)
2. Sign in to your OpenAI account (create one if needed)
3. Navigate to the **API Keys** section
4. Click **"Create new secret key"**
5. **Copy and securely store** the generated API key

<Warning>
**Security Note**

Store your API key securely and never commit it to version control. The key provides full access to your OpenAI account and billing.
</Warning>

### **2. Configure in Onyx**

1. **Access Admin Dashboard**: Navigate to your Onyx admin panel
2. **Open LLM Configuration**: Click on the **"LLM"** tab in the sidebar
3. **Add OpenAI Provider**: Select **"OpenAI"** from the available providers
4. **Enter API Key**: Paste your API key in the designated field
5. **Select Model**: Choose from available GPT models (GPT-4, GPT-4o, GPT-3.5-turbo)
6. **Test Connection**: Use the test button to verify connectivity

![OpenAI Configuration](/assets/images/gen_ai/OpenAI.png)

### **3. Model Selection**

Choose the appropriate model based on your needs:

| Model | Best For | Context Window | Cost |
|-------|----------|----------------|------|
| GPT-4 | Complex reasoning, highest quality | 8K tokens | Highest |
| GPT-4o | Balanced performance and cost | 128K tokens | Moderate |
| GPT-3.5-turbo | Simple tasks, high volume | 16K tokens | Lowest |

## Advanced Configuration

### **Custom Parameters**

You can configure additional parameters for fine-tuning behavior:

```json
{
  "temperature": 0.7,
  "max_tokens": 2048,
  "top_p": 1.0,
  "frequency_penalty": 0.0,
  "presence_penalty": 0.0
}
```

**Parameter Explanations:**
- **Temperature**: Controls randomness (0.0-2.0, lower = more focused)
- **Max Tokens**: Maximum response length
- **Top P**: Alternative to temperature for nucleus sampling
- **Frequency Penalty**: Reduces repetition of frequent tokens
- **Presence Penalty**: Reduces repetition of any tokens

### **Rate Limits and Quotas**

OpenAI implements rate limiting based on your account tier:

**Free Tier:**
- 3 requests per minute
- $5.00 monthly usage limit
- Access to GPT-3.5-turbo only

**Pay-as-you-go:**
- Higher rate limits based on usage history
- Access to all models including GPT-4
- Billing based on token usage

**Enterprise:**
- Custom rate limits and quotas
- Priority access to new models
- Enhanced support and SLAs

## Cost Management

### **Token Usage**

OpenAI billing is based on token consumption:
- **Input tokens**: Text sent to the model
- **Output tokens**: Text generated by the model
- **Both count** toward your usage costs

### **Cost Optimization Tips**

1. **Choose Appropriate Models**: Use GPT-3.5-turbo for simpler tasks
2. **Optimize Prompts**: Shorter, clearer prompts reduce token usage
3. **Set Token Limits**: Configure max_tokens to prevent excessive generation
4. **Monitor Usage**: Regularly check your OpenAI dashboard for usage patterns
5. **Enable Caching**: Use Onyx's caching features to reduce redundant API calls

### **Usage Monitoring**

Monitor your OpenAI usage through:
- **OpenAI Dashboard**: Real-time usage and billing information
- **Onyx Analytics**: Track model usage across your organization
- **API Limits**: Set up alerts for approaching rate limits

## Security Best Practices

### **API Key Management**
- **Environment Variables**: Store API keys in secure environment variables
- **Key Rotation**: Regularly rotate API keys for security
- **Access Control**: Limit who has access to API keys
- **Monitoring**: Monitor API key usage for unexpected activity

### **Data Privacy**
- **Data Retention**: OpenAI retains API data for 30 days for safety monitoring
- **Opt-out**: Enterprise customers can opt out of data retention
- **Content Filtering**: OpenAI automatically filters harmful content
- **Usage Policies**: Ensure compliance with OpenAI's usage policies

## Troubleshooting

### **Common Issues**

**Authentication Errors**
```
401 Unauthorized - Invalid API key
```
- Verify API key is correct and properly formatted
- Check if API key has been revoked or expired
- Ensure API key has appropriate permissions

**Rate Limit Errors**
```
429 Too Many Requests - Rate limit exceeded
```
- Implement exponential backoff in your requests
- Consider upgrading your OpenAI account tier
- Monitor and optimize your usage patterns

**Model Access Errors**
```
403 Forbidden - Model not accessible
```
- Verify your account has access to the requested model
- Check if you need to upgrade to access GPT-4 models
- Ensure model name is spelled correctly

### **Performance Issues**

**Slow Response Times**
- Consider using GPT-3.5-turbo for faster responses
- Reduce max_tokens parameter for shorter responses
- Use streaming responses for better user experience

**High Costs**
- Monitor token usage in OpenAI dashboard
- Optimize prompt engineering to reduce token consumption
- Consider using cheaper models for appropriate tasks

### **Quality Issues**

**Inconsistent Outputs**
- Lower temperature for more consistent responses
- Use more specific prompts with clear instructions
- Consider using system messages for context

**Incomplete Responses**
- Increase max_tokens parameter
- Check if content is being filtered by OpenAI's safety systems
- Verify prompt isn't triggering safety guidelines

## Best Practices

### **Prompt Engineering**
- **Be Specific**: Clear, detailed instructions produce better results
- **Provide Context**: Include relevant background information
- **Use Examples**: Show the model what you want with examples
- **Set Expectations**: Clearly state the desired format and length

### **Production Deployment**
- **Implement Retries**: Handle temporary failures with exponential backoff
- **Monitor Usage**: Track costs and performance metrics
- **Set Quotas**: Implement usage limits to prevent unexpected costs
- **Cache Responses**: Reduce API calls for repeated queries

### **Model Selection Strategy**
- **Start with GPT-3.5-turbo**: Evaluate if it meets your needs before upgrading
- **A/B Testing**: Compare models on your specific use cases
- **Cost vs Quality**: Balance performance requirements with budget constraints

## Integration Examples

### **Basic Integration**

```python
import openai

# Configure OpenAI client
client = openai.OpenAI(api_key="your-api-key")

# Make a request
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "What is the capital of France?"}
    ],
    max_tokens=100,
    temperature=0.7
)

print(response.choices[0].message.content)
```

### **Error Handling**

```python
import openai
from openai import OpenAI

client = OpenAI(api_key="your-api-key")

try:
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": "Hello!"}]
    )
except openai.RateLimitError:
    print("Rate limit exceeded. Please try again later.")
except openai.AuthenticationError:
    print("Invalid API key. Please check your credentials.")
except Exception as e:
    print(f"An error occurred: {e}")
```

## Getting Help

For OpenAI-specific issues:
- **OpenAI Documentation**: [https://platform.openai.com/docs](https://platform.openai.com/docs)
- **OpenAI Support**: Available through your OpenAI dashboard
- **Community Forum**: [OpenAI Community](https://community.openai.com/)

For Onyx integration support:
- **Onyx Slack**: Join our [community](https://join.slack.com/t/onyx-dot-app/shared_invite/zt-34lu4m7xg-TsKGO6h8PDvR5W27zTdyhA)
- **Documentation**: Return to the [LLM Overview](../getting_started/llm) for general guidance
- **GitHub Issues**: Report integration problems on our [repository](https://github.com/onyx-dot-app/onyx)

OpenAI provides reliable, high-quality language models that integrate seamlessly with Onyx, making it an excellent choice for most production deployments. 