---
title: Google Vertex AI Configuration
description: "Configure Google Vertex AI models for Onyx"
icon: "google"
---

Configure Onyx to use Google Vertex AI, providing access to Google's latest language models including Gemini Pro and PaLM 2. Vertex AI offers enterprise-grade AI services with robust security, compliance, and scaling capabilities within the Google Cloud ecosystem.

## Available Models

Google Vertex AI provides access to several powerful language models:

### **Gemini Family**
- **Gemini Pro** - Advanced reasoning and multimodal capabilities
- **Gemini Flash** - Fast and efficient for many tasks
- **Gemini Ultra** - Most capable model (limited availability)

### **PaLM Family**
- **PaLM 2** - Strong performance across various tasks
- **Codey** - Specialized for code generation and analysis
- **Chat-Bison** - Optimized for conversational use cases

### **Model Recommendations**
- **Production Use**: Gemini Pro for best overall performance
- **High Volume**: Gemini Flash for speed and efficiency
- **Code Tasks**: Codey models for programming-related tasks
- **Chat Applications**: Chat-Bison for conversational interfaces

## Authentication Methods

Vertex AI offers two primary authentication methods for integrating with Onyx:

1. **gcloud CLI Authentication** - Simpler setup for development
2. **Service Account Authentication** - Recommended for production deployments

## Method 1: gcloud CLI Authentication

This method is ideal for development environments and quick setup.

### **Prerequisites**
- Google Cloud account with Vertex AI API enabled
- Administrative access to install gcloud CLI
- Access to the machine running Onyx

### **Setup Process**

#### **1. Install gcloud CLI**
1. Download and install the [Google Cloud SDK](https://cloud.google.com/sdk/docs/install)
2. Choose the appropriate installer for your operating system
3. Follow the installation instructions for your platform

#### **2. Authenticate with gcloud**
1. Open a terminal on the machine where Onyx is running
2. Run the authentication command:
   ```bash
   gcloud auth application-default login
   ```
3. Follow the browser-based authentication flow
4. Grant necessary permissions to access Vertex AI

#### **3. Configure Custom LLM Provider in Onyx**

1. **Access Admin Dashboard**: Navigate to your Onyx admin panel
2. **Add Custom Provider**: Select "Custom LLM Provider" from the available options
3. **Configure Provider Settings**:

![Vertex AI CLI Setup](/assets/images/gen_ai/vertex_ai/cli-1.png)

**Configuration Details:**
```
Provider Name: Vertex AI
Model Name: vertex_ai/gemini-pro
API Base: (leave empty - uses default Vertex AI endpoint)
API Key: (leave empty - uses gcloud authentication)
```

![Vertex AI CLI Config](/assets/images/gen_ai/vertex_ai/cli-2.png)

4. **Additional Settings**:
   - Set your Google Cloud Project ID
   - Specify region if different from default
   - Configure any custom parameters

![Vertex AI CLI Complete](/assets/images/gen_ai/vertex_ai/cli-3.png)

#### **4. Test Configuration**
1. **Verify Authentication**: Test the connection using the Onyx interface
2. **Send Test Query**: Send a simple query to verify model response
3. **Check Logs**: Review logs for any authentication or connectivity issues

## Method 2: Service Account Authentication

This method is recommended for production deployments as it provides better security and doesn't require interactive authentication.

### **Prerequisites**
- Google Cloud Console access
- Permissions to create service accounts
- Vertex AI API enabled in your project

### **Setup Process**

#### **1. Create Service Account**

1. Navigate to the [Google Cloud Console](https://console.cloud.google.com/)
2. Go to **IAM & Admin** → **Service Accounts**

![Service Account Creation](/assets/images/gen_ai/vertex_ai/service-acc-1.png)

3. **Create Service Account**:
   - Click **"+ Create Service Account"**
   - **Name**: `onyx-vertex-ai` (or your preferred name)
   - **Description**: "Service account for Onyx Vertex AI integration"

4. **Assign Roles**:
   - **Vertex AI Administrator**: Full access to Vertex AI resources
   - **Vertex AI User**: Alternative with more limited permissions
   - Click **"Create and Continue"**

#### **2. Generate JSON Credentials**

1. **Access Service Account**: Click on the created service account
2. **Navigate to Keys Tab**: Select the "Keys" tab
3. **Add New Key**: Click "Add Key" → "Create new key"

![Service Account Key](/assets/images/gen_ai/vertex_ai/service-acc-2.png)

4. **Select JSON Format**: Choose "JSON" as the key type
5. **Download**: Click "Create" to download the JSON credentials file
6. **Secure Storage**: Store the JSON file securely and never commit to version control

### **3. Configure Onyx with Service Account**

#### **Upload Credentials**
1. **Access Admin Dashboard**: Navigate to your Onyx admin panel
2. **Select Vertex AI Setup**: Click "Set up" next to "GCP Vertex AI"
3. **Upload JSON File**: Drag and drop your credentials file or click to select

![Onyx Service Account Config](/assets/images/gen_ai/vertex_ai/onyx-service-acc-1.png)

#### **Configure Location (Optional)**
1. **Select Region**: Choose your preferred Vertex AI region
2. **Available Regions**: Select from supported locations:

**Americas:**
- us-central1, us-east1, us-east4, us-east5
- us-south1, us-west1, us-west2, us-west3, us-west4
- northamerica-northeast1, northamerica-northeast2
- southamerica-east1

**Europe:**
- europe-central2, europe-north1, europe-southwest1
- europe-west1, europe-west2, europe-west3
- europe-west4, europe-west6, europe-west8, europe-west9

**Asia Pacific:**
- asia-east1, asia-east2, asia-northeast1
- asia-northeast2, asia-northeast3, asia-south1
- asia-south2, asia-southeast1, asia-southeast2
- australia-southeast1, australia-southeast2

**Other Regions:**
- me-west1, africa-south1

![Onyx Service Account Location](/assets/images/gen_ai/vertex_ai/onyx-service-acc-2.png)

## Advanced Configuration

### **Regional Considerations**

**Region Selection Factors:**
- **Latency**: Choose regions closest to your users
- **Data Residency**: Comply with data location requirements
- **Model Availability**: Some models may not be available in all regions
- **Pricing**: Regional pricing variations may apply

**Recommended Regions:**
- **US-Central1**: Primary US region, first to receive new features
- **Europe-West1**: Primary European region
- **Asia-Southeast1**: Primary Asia Pacific region

### **Model Parameters**

Configure Vertex AI models with these parameters:

```json
{
  "temperature": 0.7,
  "max_output_tokens": 2048,
  "top_p": 0.95,
  "top_k": 40,
  "candidate_count": 1,
  "stop_sequences": []
}
```

**Parameter Explanations:**
- **temperature**: Controls randomness (0.0-1.0)
- **max_output_tokens**: Maximum response length
- **top_p**: Nucleus sampling threshold
- **top_k**: Top-k sampling limit
- **candidate_count**: Number of response candidates
- **stop_sequences**: Text sequences that halt generation

### **Quotas and Limits**

Vertex AI implements quotas and rate limits:

**Request Quotas:**
- **Per-minute limits**: Based on model and region
- **Per-day limits**: Daily request allowances
- **Concurrent requests**: Maximum simultaneous requests

**Token Limits:**
- **Input tokens**: Maximum tokens per request
- **Output tokens**: Maximum generated tokens
- **Context window**: Model-specific context limits

## Cost Management

### **Pricing Structure**

Vertex AI pricing is based on:
- **Model Usage**: Per-request or per-token pricing
- **Compute Resources**: If using custom models
- **Network Egress**: Data transfer costs
- **Storage**: For stored models and data

### **Cost Optimization**

1. **Monitor Usage**: Use Google Cloud Console billing reports
2. **Right-Size Models**: Choose appropriate models for each task
3. **Regional Optimization**: Consider regional pricing differences
4. **Request Optimization**: Minimize unnecessary API calls
5. **Batch Processing**: Group requests when possible

### **Budget Management**

Set up budget alerts:
```bash
# gcloud CLI example
gcloud billing budgets create \
  --display-name="Vertex AI Budget" \
  --budget-amount=1000.00 \
  --threshold-percent=50,90 \
  --all-projects
```

## Security and Compliance

### **Data Protection**
- **Encryption**: All data encrypted in transit and at rest
- **Access Control**: IAM-based access management
- **Audit Logging**: Comprehensive activity logging
- **Data Location**: Control over data processing regions

### **Compliance Standards**
Google Cloud Vertex AI supports:
- **SOC 2/3**: Service Organization Control compliance
- **ISO 27001**: Information security management
- **PCI DSS**: Payment Card Industry standards
- **HIPAA**: Healthcare data protection (with BAA)
- **GDPR**: European data protection compliance

### **Service Account Security**
- **Principle of Least Privilege**: Grant minimum necessary permissions
- **Key Rotation**: Regularly rotate service account keys
- **Access Monitoring**: Monitor service account usage
- **Secure Storage**: Never store keys in code repositories

## Troubleshooting

### **Authentication Issues**

#### **gcloud CLI Problems**
```
Error: Could not automatically determine credentials
```
**Solutions:**
- Verify gcloud is installed correctly
- Run `gcloud auth application-default login` again
- Check if credentials file exists: `~/.config/gcloud/application_default_credentials.json`
- Verify project ID is set: `gcloud config get-value project`

#### **Service Account Issues**
```
403 Forbidden - Permission denied
```
**Solutions:**
- Verify service account has correct roles
- Check if Vertex AI API is enabled in your project
- Confirm JSON key file is valid and not expired
- Verify project ID matches the one in credentials

### **API and Model Issues**

#### **Model Not Found**
```
404 Model not found
```
**Solutions:**
- Check if model name is spelled correctly
- Verify model is available in your selected region
- Confirm you have access to the requested model

#### **Quota Exceeded**
```
429 Quota exceeded
```
**Solutions:**
- Check quotas in Google Cloud Console
- Request quota increases through support
- Implement exponential backoff in requests
- Consider distributing load across regions

### **Performance Issues**

#### **High Latency**
**Diagnostic Steps:**
- Check selected region proximity to users
- Monitor network connectivity
- Review model complexity and parameters
- Consider using faster models for time-sensitive tasks

#### **Inconsistent Responses**
**Solutions:**
- Lower temperature for more deterministic outputs
- Use consistent system prompts
- Monitor and log request/response patterns

## Best Practices

### **Production Deployment**

1. **Use Service Accounts**: Avoid user credentials in production
2. **Implement Monitoring**: Set up comprehensive logging and alerting
3. **Error Handling**: Robust retry logic with exponential backoff
4. **Security**: Follow Google Cloud security best practices
5. **Scalability**: Design for horizontal scaling and load distribution

### **Development Workflow**

1. **Local Development**: Use gcloud CLI for development
2. **Testing**: Comprehensive testing across different models
3. **Staging**: Use service accounts in staging environments
4. **Monitoring**: Implement request/response logging
5. **Documentation**: Document model choices and configurations

### **Cost Optimization**

1. **Model Selection**: Use appropriate models for each task
2. **Request Batching**: Group similar requests
3. **Caching**: Cache responses for repeated queries
4. **Monitoring**: Regular usage and cost reviews
5. **Optimization**: Continuously optimize prompt engineering

## Integration Examples

### **Basic Vertex AI Integration**

```python
from vertexai.generative_models import GenerativeModel
import vertexai

# Initialize Vertex AI
vertexai.init(project="your-project-id", location="us-central1")

# Create model instance
model = GenerativeModel("gemini-pro")

# Generate response
response = model.generate_content("What is quantum computing?")
print(response.text)
```

### **With Service Account**

```python
import os
from google.oauth2 import service_account
from vertexai.generative_models import GenerativeModel
import vertexai

# Load service account credentials
credentials = service_account.Credentials.from_service_account_file(
    "path/to/your/credentials.json"
)

# Initialize with credentials
vertexai.init(
    project="your-project-id",
    location="us-central1",
    credentials=credentials
)

model = GenerativeModel("gemini-pro")
response = model.generate_content("Hello Vertex AI!")
```

### **Error Handling**

```python
from google.api_core import exceptions
from vertexai.generative_models import GenerativeModel
import vertexai

vertexai.init(project="your-project-id", location="us-central1")
model = GenerativeModel("gemini-pro")

try:
    response = model.generate_content("Your prompt here")
    print(response.text)
except exceptions.PermissionDenied:
    print("Permission denied. Check your credentials and IAM roles.")
except exceptions.ResourceExhausted:
    print("Quota exceeded. Try again later or request quota increase.")
except exceptions.NotFound:
    print("Model not found. Check model name and region availability.")
except Exception as e:
    print(f"An error occurred: {e}")
```

## Migration and Integration

### **From Other Providers**

When migrating from other LLM providers:
1. **Model Mapping**: Compare capabilities and select equivalent Vertex AI models
2. **API Differences**: Adapt to Vertex AI's API structure
3. **Authentication**: Implement Google Cloud authentication
4. **Testing**: Comprehensive testing with your specific use cases
5. **Gradual Migration**: Phase migration to minimize disruption

### **Multi-Provider Setup**

Using Vertex AI alongside other providers:
- **Load Balancing**: Distribute requests across providers
- **Fallback Strategy**: Use Vertex AI as backup for other providers
- **A/B Testing**: Compare model performance across providers
- **Cost Optimization**: Route requests based on cost considerations

## Getting Help

For Google Vertex AI support:
- **Google Cloud Support**: Available with paid support plans
- **Documentation**: [Vertex AI Documentation](https://cloud.google.com/vertex-ai/docs)
- **Community**: Google Cloud community forums
- **Training**: Google Cloud training resources

For Onyx integration help:
- **Onyx Slack**: Join our [community](https://join.slack.com/t/onyx-dot-app/shared_invite/zt-34lu4m7xg-TsKGO6h8PDvR5W27zTdyhA)
- **Documentation**: Return to [LLM Overview](../getting_started/llm)
- **Issues**: Report problems on [GitHub](https://github.com/onyx-dot-app/onyx)

Google Vertex AI provides enterprise-grade access to Google's latest AI models with comprehensive security, compliance, and scaling capabilities, making it an excellent choice for organizations already using Google Cloud or requiring advanced AI capabilities. 